{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "---\n",
    "Это нужно знать:\n",
    " 1. Аугментация данных\n",
    " 2. Предобработка данных\n",
    " 3. Инициализация\n",
    " 4. Процесс обучения\n",
    " 5. Выбор функции активации\n",
    " 6. Визуализация\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Аугментация данных\n",
    "**Аугментация данных** - это \"раздутие\" датасета для тренировки нейроной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание обучающих  примеров из искусственных изображений\n",
    "Можно взять несколько шаблонов / «идеальных» примеров (например, наборов шрифтов) и с помощью различных искажений создать необходимое число примеров для обучения. Можно использовать следующие искажения:\n",
    "1. Геометрические (афинные, проективные, ...).\n",
    "2. Яркостные/цветовые.\n",
    "3. Замена фона.\n",
    "4. Искажения, характерные для решаемой задачи: блики, шумы, размытие и т. д.\n",
    "\n",
    "**Сдвиги:**\n",
    "\n",
    "![](img/sdvigi.png)\n",
    "\n",
    "**Повороты:**\n",
    "\n",
    "![](img/povoroty.png)\n",
    "\n",
    "**Дополнительные линии на изображениях:**\n",
    "\n",
    "![](img/doplin.png)\n",
    "\n",
    "**Блики:**\n",
    "\n",
    "![](img/bliki.png)\n",
    "\n",
    "**Дефокус:**\n",
    "\n",
    "![](img/defocus.png)\n",
    "\n",
    "**Сжатия и растяжения вдоль осей:** \n",
    "\n",
    "![](img/szhatie.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Предобработка данных\n",
    "Итак, мы получили большое количество обучающих изображений. Теперь необходимо выполнить их предобработку. Далее мы рассмотрим несколько вариантов этой процедуры.\n",
    "\n",
    "Одним из наиболее распространенных методов предобработки является центрирование данных к нулю (zero-centering) и последующая нормализация (normalization). Для этого понадобится две строки кода на Python:\n",
    "```python\n",
    "X -= np.mean(X, axis = 0) # zero-center\n",
    "X /= np.std(X, axis = 0) # normalize\n",
    "```\n",
    "где X представляет собой массив входных данных (количество элементов × количество измерений). Другая форма этой предобработки нормализует каждое измерение таким образом, чтобы минимальное и максимальное значение по данному измерению были равны –1 и 1 соответственно. Данную предобработку имеет смысл применять только в том случае, когда есть основания полагать, что различные входные признаки имеют различный масштаб (или единицы измерения), но при этом обладают примерно одинаковой ценностью для модели. В случае изображений, относительные масштабы пикселей исходно примерно одинаковы (и находятся в интервале от 0 до 255), поэтому нет строгой необходимости выполнять данную предобработку.\n",
    "\n",
    "Другой метод предобработки, аналогичный первому, называется PCA отбеливание (PCA whitening). Данные сначала центрируются, как описано выше, а затем вычисляется ковариационная матрица, описывающая структуру корреляций в данных:\n",
    "```python\n",
    "X -= np.mean(X, axis = 0) # zero-center\n",
    "X /= cov = np.dot(X.T, X) / X.shape[0] # compute the covariance matrix\n",
    "```\n",
    "Далее мы выполняем декорреляцию, проецируя исходные данные (центрированные) на собственный базис (eigenbasis):\n",
    "```python\n",
    "U,S,V = np.linalg.svd(cov) # compute the SVD factorization of the data covariance matrix\n",
    "Xrot = np.dot(X, U) # decorrelate the data\n",
    "```\n",
    "Последним этапом является отбеливание. Мы берем данные в собственном базисе и делим каждое измерение на собственное значение, чтобы нормализовать масштаб:\n",
    "```python\n",
    "Xwhite = Xrot / np.sqrt(S + 1e-5) # divide by the eigenvalues (which are square roots of the singular values)\n",
    "```\n",
    "Обратите внимание, мы прибавляем малую константу 1e–5, чтобы предотвратить деление на ноль. Недостатком этого преобразования является то, что в его результате может быть значительно усилен шум в данных. Это связано с тем, что данный метод преобразует все измерения к одинаковому размеру, в том числе, измерения, обладающие малой дисперсией и являющиеся в своем большинстве шумом. На практике этот недостаток можно нивелировать с помощью более сильного сглаживания (т.е. увеличив значение малой константы).\n",
    "\n",
    "Для полноты мы рассмотрели несколько методов предобработки. Следует отметить, что в случае сверточных сетей последний метод не применяется, в то время как центрирование данных является необходимым. Кроме того, часто выполняется нормализация каждого пикселя.\n",
    "\n",
    "![](img/ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Инициализация\n",
    "Данные готовы, но прежде чем начать обучение сети, необходимо инициализировать ее параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация малыми случайными значениями\n",
    "Таким образом, нам нужно, чтобы веса были близки к нулю, но не равны ему. Для этого мы можем инициализировать их малыми случайными значениями очень близкими к нулю, что позволит нарушить симметрию. В результате, все исходные веса будут случайными и уникальными, следовательно, обновляться они будут по-разному, что нам и нужно. Вычислить веса можно следующим образом:\n",
    "\n",
    "*weights ~ 0,001 × N(0, 1)*\n",
    "\n",
    "где *N(0, 1)* – нормальное распределение с математическим ожиданием, равным 0, и среднеквадратическим отклонением, равным 1. Кроме того, можно использовать малые случайные значения из равномерного распределения, но на практике этот подход не оказывает существенного влияния на результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Процесс обучения\n",
    "\n",
    "Итак, все готово. Приступим к обучению глубоких сетей!\n",
    "\n",
    "### Фильтры и размер объединения (pooling size)\n",
    "\n",
    "Желательно, чтобы размер входных изображений представлял собой степень двойки, например, 32 (CIFAR-10), 64, 224 (ImageNet), 384, 512 и т.д. Кроме того, важно применять малый фильтр (например, 3 × 3) и малый шаг (stride) (например, 1) с заполнением нулями (zero-padding),\n",
    "\n",
    "![](img/ex1.png)\n",
    "\n",
    "что позволяет не только уменьшить количество параметров, но и повысить точность сети в целом. Частный случай, упомянутый выше (фильтр 3 × 3 с шагом 1), позволяет сохранить пространственный размер карт признаков и изображений. Рекомендуемый размер объединения составляет 2 × 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Выбор функции активации\n",
    "Одним из важнейших аспектов глубокой нейронной сети является функция активации (activation function), которая привносит в сеть нелинейность. Далее мы рассмотрим распространенные функции активации и дадим рекомендации по их выбору.\n",
    "\n",
    "![](img/neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперболический тангенс\n",
    "\n",
    "![](img/thx.png)\n",
    "\n",
    "Гиперболический тангенс (hyperbolic tangent, tanh) принимает на входе произвольное вещественное число, а на выходе дает вещественное число в интервале от –1 до 1.\n",
    "\n",
    "Формула гиперболического тангенса:\n",
    "             <p><h1>$th(x)=\\frac{e^x+e^{-x}}{e^x-e^{-x}}$</h1></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU\n",
    "![](img/relu.png)\n",
    "\n",
    "В последние годы большую популярность приобрела функция активации под названием «выпрямитель» (rectifier, по аналогии с однополупериодным выпрямителем в электротехнике). Нейроны с данной функцией активации называются ReLU (rectified linear unit). ReLU имеет следующую формулу f(x) = max(0, x) и реализует простой пороговый переход в нуле.\n",
    "\n",
    "В настоящее время существует целое семейство различных модификаций ReLU:\n",
    "\n",
    "![](img/relus.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
